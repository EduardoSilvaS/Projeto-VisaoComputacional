{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Definições Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device(on_gpu=True):\n",
    "    has_mps = torch.backends.mps.is_available()\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    return \"mps\" if (has_mps and on_gpu) \\\n",
    "            else \"cuda\" if (has_cuda and on_gpu) \\\n",
    "            else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = set_device(on_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carregamento de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Definindo transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = 'RiceLeafs'\n",
    "\n",
    "# Definimos as transformações para os dados de treinamento.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                                                       # Converte a imagem para um tensor PyTorch;\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.5, 1.0)),                    # Corta e redimensiona aleatoriamente a imagem para 224x224 pixels;\n",
    "    transforms.RandomHorizontalFlip(p=0.5),                                      # Aplica flip horizontal aleatório;\n",
    "    transforms.RandomChoice([\n",
    "        transforms.RandomRotation((0, 0)),                                          # Não gira (0 graus)\n",
    "        transforms.RandomRotation((90, 90)),                                        # Gira exatamente 90 graus\n",
    "        transforms.RandomRotation((180, 180)),                                      # Gira exatamente 180 graus\n",
    "        transforms.RandomRotation((270, 270))                                       # Gira exatamente 270 graus\n",
    "    ]),                                      \n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),                        # Ajusta brilho e contraste aleatoriamente;      \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normaliza a imagem com médias e desvios padrão do ImageNet.\n",
    "])\n",
    "\n",
    "# As transformações de validação são apenas de redimensionamento e normalização.\n",
    "val_transform = None                                                             # Vamos usar as transformações padrão do modelo efficientNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Criando Datasets e DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes carregadas: ['BrownSpot', 'Healthy', 'Hispa', 'LeafBlast']\n"
     ]
    }
   ],
   "source": [
    "# Para treino, usaremos 'RiceLeafs/train'\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=os.path.join(ROOT_DIR, 'train'),\n",
    "    transform=train_transform # Aplica as tranformações de treinamento  \n",
    ")\n",
    "\n",
    "# Para validação, usaremos 'RiceLeafs/validation'\n",
    "val_dataset = None # Vamos usar as transformações padrão do modelo efficientNet.\n",
    "\n",
    "# Vamos salvar separadamente os nomes das classes para referência futura.\n",
    "class_names = train_dataset.classes\n",
    "print(f\"Classes carregadas: {class_names}\")\n",
    "\n",
    "# Criamos os DataLoaders com batch size de 32\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=os.cpu_count() // 2 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Escolha do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rodando em: cuda\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"Rodando em: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1 # Definimos os pesos pré-treinados do ImageNet\n",
    "model = models.efficientnet_b0(weights=weights)        # Carregamos o modelo EfficientNet-B0 pré-treinado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Aplicando as tranformações de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = weights.transforms()                   # Usamos as transformações recomendadas para validação\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    root=os.path.join(ROOT_DIR, 'validation'),\n",
    "    transform=val_transform                            # Aplica as tranformações de validação do modelo\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=os.cpu_count() // 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Alterando a camada final do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo do modelo: cuda:0\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():    # Congelamos todos os parâmetros do modelo pré-treinado para evitar que sejam atualizados durante o treinamento\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modificamos a camada final para o número correto de classes\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(in_features=num_ftrs, out_features=NUM_CLASSES)\n",
    "\n",
    "# Mover o modelo para o dispositivo\n",
    "model.to(device)\n",
    "print(f\"Dispositivo do modelo: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()                       # Função de perda para classificação multi-classe\n",
    "L2_LAMBDA = 0.1                                         # Fator de regularização L2\n",
    "L1_LAMBDA = 0.001                                       # Fator de regularização L1    \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=L2_LAMBDA)  # Otimizador Adam com regularização L2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Loop de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'train_loss': [], # Histórico de perda de treinamento\n",
    "            'train_acc': [], # Histórico de acurácia de treinamento\n",
    "            'val_loss': [],  # Histórico de perda de validação\n",
    "            'val_acc': []}   # Histórico de acurácia de validação\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, num_epochs=10):\n",
    "    start_time = time.time() # Início do cronômetro\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train() # Modo de treinamento\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zera gradientes do otimizador\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Regularização L1\n",
    "            # l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            # total_loss = loss + L1_LAMBDA * l1_norm\n",
    "\n",
    "            # Backward pass e otimização\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Estatísticas\n",
    "            running_loss += loss.item() * BATCH_SIZE\n",
    "            running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "    \n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'Treino concluído em {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Acurácia final de treinamento: {history[\"train_acc\"][-1]:.4f}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Epoch 2/10\n",
      "----------\n",
      "Epoch 3/10\n",
      "----------\n",
      "Epoch 4/10\n",
      "----------\n",
      "Epoch 5/10\n",
      "----------\n",
      "Epoch 6/10\n",
      "----------\n",
      "Epoch 7/10\n",
      "----------\n",
      "Epoch 8/10\n",
      "----------\n",
      "Epoch 9/10\n",
      "----------\n",
      "Epoch 10/10\n",
      "----------\n",
      "Treino concluído em 29m 36s\n",
      "Acurácia final de treinamento: 0.6368\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, criterion, optimizer, train_loader, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Fine-Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o fine-tuning do modelo...\n",
      "Epoch 1/15\n",
      "----------\n",
      "Epoch 2/15\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():    # Descongelamos todos os parâmetros do modelo para permitir o fine-tuning\n",
    "    param.requires_grad = True\n",
    " \n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.0001) # Otimizador Adam para todo o modelo com uma taxa de aprendizado menor\n",
    "\n",
    "print(\"Iniciando o fine-tuning do modelo...\")\n",
    "trained_model = train_model(trained_model, criterion, optimizer_ft, train_loader, num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, criterion, num_epochs=10):\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "\n",
    "        with torch.no_grad(): # Desliga cálculo de gradientes para validação\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
    "\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc.item())\n",
    "\n",
    "        # Guardar o modelo se for o melhor até agora\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - start_time\n",
    "    print(f'Treino concluído em {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Melhor Acurácia de Validação: {best_acc:.4f}')\n",
    "\n",
    "    # Carregar os melhores pesos no modelo final\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Epoch 2/10\n",
      "----------\n",
      "Epoch 3/10\n",
      "----------\n",
      "Epoch 4/10\n",
      "----------\n",
      "Epoch 5/10\n",
      "----------\n",
      "Epoch 6/10\n",
      "----------\n",
      "Epoch 7/10\n",
      "----------\n",
      "Epoch 8/10\n",
      "----------\n",
      "Epoch 9/10\n",
      "----------\n",
      "Epoch 10/10\n",
      "----------\n",
      "Treino concluído em 2m 36s\n",
      "Melhor Acurácia de Validação: 0.2906\n"
     ]
    }
   ],
   "source": [
    "trained_model = validate_model(trained_model, val_loader, criterion, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.5, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomChoice(\n",
      "    RandomRotation(degrees=[0.0, 0.0], interpolation=nearest, expand=False, fill=0)\n",
      "    RandomRotation(degrees=[90.0, 90.0], interpolation=nearest, expand=False, fill=0)\n",
      "    RandomRotation(degrees=[180.0, 180.0], interpolation=nearest, expand=False, fill=0)\n",
      "    RandomRotation(degrees=[270.0, 270.0], interpolation=nearest, expand=False, fill=0)\n",
      ")(p=None)\n",
      "    ColorJitter(brightness=(0.9, 1.1), contrast=(0.9, 1.1), saturation=None, hue=None)\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(train_transform)\n",
    "print(val_transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
